# A1Facts Manual 300-Case Evaluation Results

## üèÜ **PARALLEL EVALUATION COMPLETE!**
**Date**: October 15, 2025  
**Dataset**: 300 high-quality manual test cases  
**Mode**: Parallel processing (5x faster)  
**Total Time**: ~2.3 hours (vs 10+ hours sequential)  

---

## üìä **FINAL RANKINGS - STRICT ACCURACY**

| Rank | Model | Strict Accuracy | Cases Correct | Validity Acc | Reliability Acc |
|------|-------|----------------|---------------|--------------|-----------------|
| ü•á **1st** | **gemini-2.5-flash** | **13.7%** | **41/300** | **46.5%** | **38.5%** |
| ü•à **2nd** | **gemini-2.5-pro** | **12.3%** | **37/300** | **44.4%** | **47.3%** |
| ü•â **3rd** | **gpt-4-turbo** | **9.7%** | **29/300** | **40.3%** | **33.5%** |
| 4th | **gemini-flash** | **8.0%** | **24/300** | **53.0%** | **32.7%** |
| 5th | **gemini-2.0-flash** | **2.3%** | **7/300** | **41.7%** | **41.7%** |

---

## üéØ **KEY INSIGHTS**

### **Strict Accuracy Definition**
- **BOTH** validity (1-6) AND reliability (A-F) must be correct
- Most challenging metric - requires perfect dual prediction
- Range: 2.3% - 13.7% across all models

### **Performance Patterns**
- **üèÜ Gemini 2.5 Flash WINS** - Best overall performance (13.7%)
- **üìà Validity vs Reliability**: All models stronger on validity than reliability
- **üîÑ Trade-offs**: gemini-flash has highest validity (53%) but lower strict accuracy

### **Model Characteristics**
1. **gemini-2.5-flash**: Balanced leader, best strict accuracy
2. **gemini-2.5-pro**: Strong reliability detection (47.3%)
3. **gpt-4-turbo**: Consistent performance across metrics
4. **gemini-flash**: Excellent validity detection (53%) but struggles with reliability
5. **gemini-2.0-flash**: Significantly underperforms (2.3%)

---

## üìà **DETAILED METRICS BY VALIDITY LEVEL**

### **Validity 1 (Confirmed Facts) - 60 cases**
- **Best**: gemini-2.5-pro (90% recall, 85.7% F1)
- **Good**: gemini-flash (94% recall, 82.5% F1)
- **Moderate**: gpt-4-turbo (70% recall, 65.1% F1)

### **Validity 2 (Probably True) - 54 cases**
- **Best**: gemini-flash (44% recall, 47.8% F1)
- **Moderate**: All other models 30-40% F1 range

### **Validity 3 (Possibly True) - 54 cases**
- **Best**: gemini-2.5-flash (32% recall, 44.7% F1)
- **Consistent**: Most models struggle with this ambiguous category

### **Validity 4 (Doubtful) - 54 cases**
- **Major Challenge**: All models struggle significantly
- gemini-2.5-pro: 0% performance
- gpt-4-turbo: 33.0% F1 (best of poor performance)

### **Validity 5 (Improbable) - 36 cases**
- **Perfect Recall**: gemini-flash and gemini-2.5-flash (100% recall)
- **Balanced**: gpt-4-turbo (83% recall, 50% F1)

### **Validity 6 (Cannot Judge) - 42 cases**
- **Best**: gemini-flash (50% recall, 53.7% F1)
- **Struggle**: Most models find this category difficult

---

## üîç **RELIABILITY PERFORMANCE BY GRADE**

### **Grade A (Completely Reliable) - 50 cases**
- **Excellent Recall**: All models 78-98% recall
- **Best Precision**: gpt-4-turbo (45.6%)
- **Challenge**: High recall but low precision (over-predicting A)

### **Grade B (Usually Reliable) - 50 cases**
- **Major Weakness**: All models struggle significantly
- **Best**: gemini-2.5-pro (14.1% F1)
- **Issue**: Confusion between A and B ratings

### **Grade C (Fairly Reliable) - 50 cases**
- **Complete Failure**: All models 0% performance
- **Critical Gap**: Models cannot distinguish C-level reliability

### **Grade D (Not Usually Reliable) - 50 cases**
- **Best**: gemini-2.5-pro (52.5% F1)
- **Moderate**: gemini-2.5-flash (45.1% F1)

### **Grade E (Unreliable) - 50 cases**
- **Best**: gemini-2.5-pro (64.4% F1, 75.7% recall)
- **Good**: gemini-2.5-flash (61.0% F1)

### **Grade F (Completely Unreliable) - 50 cases**
- **Best**: gemini-2.5-pro (52.6% F1)
- **Challenge**: Most models under-predict F ratings

---

## üöÄ **PARALLEL PROCESSING SUCCESS**

### **Technical Achievement**
- ‚úÖ **5 models ran simultaneously** (instead of sequential)
- ‚úÖ **Separate Comet experiments** for each model
- ‚úÖ **Complete 300-case evaluation** in ~2.3 hours
- ‚úÖ **Live progress tracking** for all models

### **Comet ML Experiments**
1. **gpt-4-turbo**: [5e189bf369a04904b434277e1a1457d5](https://www.comet.com/sidhant-garg/testing/5e189bf369a04904b434277e1a1457d5)
2. **gemini-2.5-flash**: [4c98fb9763134a87aa9f4ab28e707195](https://www.comet.com/sidhant-garg/testing/4c98fb9763134a87aa9f4ab28e707195)
3. **gemini-2.5-pro**: [b3fa8fe394314eb28eca28e726fb8cc6](https://www.comet.com/sidhant-garg/testing/b3fa8fe394314eb28eca28e726fb8cc6)
4. **gemini-2.0-flash**: [788c3fc9a7ee40e2bf143ec60663b637](https://www.comet.com/sidhant-garg/testing/788c3fc9a7ee40e2bf143ec60663b637)
5. **gemini-flash**: [595a4835dd024748b5ec930ce87b5c22](https://www.comet.com/sidhant-garg/testing/595a4835dd024748b5ec930ce87b5c22)

---

## üéØ **RESEARCH IMPLICATIONS**

### **Model Capabilities**
1. **Validity Assessment**: Models reasonably good (40-53% accuracy)
2. **Reliability Assessment**: Major challenge (33-47% accuracy)
3. **Combined Performance**: Significant room for improvement (2-14% strict accuracy)

### **Task Difficulty**
- **Easiest**: Validity 1 (Confirmed) - clear factual verification
- **Hardest**: Validity 4 (Doubtful) - requires nuanced judgment
- **Reliability Gap**: Grade C completely undetectable by all models

### **Practical Applications**
- Current models need human oversight for reliability assessment
- Validity ratings more trustworthy than reliability scores
- Best use: Pre-screening with human verification

---

## üìã **DATASET VALIDATION**
- ‚úÖ **Perfect Balance**: 50 cases per reliability grade (A-F)
- ‚úÖ **Validity Distribution**: Appropriate spread across difficulty levels
- ‚úÖ **65 Domain Coverage**: Comprehensive academic field representation
- ‚úÖ **Quality Assurance**: Zero redundancy, realistic source-content matching

**Generated**: October 15, 2025 16:54 PST
**Evaluation Mode**: Parallel Processing (A1Facts Triangulation Methodology)